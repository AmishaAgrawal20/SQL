{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\programdata\\anaconda\\lib\\site-packages (3.1.2)\n",
      "Requirement already satisfied: py4j==0.10.9 in c:\\programdata\\anaconda\\lib\\site-packages (from pyspark) (0.10.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType, IntegerType\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import sum,count\n",
    "from pyspark.sql.functions import stddev_pop\n",
    "from pyspark.sql.functions import max\n",
    "from pyspark.sql.functions import mean ,corr,max, min,stddev_pop ,stddev_samp,covar_pop,covar_samp\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc =SparkContext.getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType,StructField,StringType,IntegerType\n",
    "order_items = [(1,2,3,5,49000),\n",
    "                 (2,2,2,5,49000),\n",
    "                 (3,3,3,5,49000),\n",
    "                 (4,4,2,6,49000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"order_id\",IntegerType(),True),\n",
    "    StructField(\"item_id\",StringType(),True),\n",
    "    StructField(\"product_id\",StringType(),True),\n",
    "    StructField(\"quantity\",StringType(),True),\n",
    "    StructField(\"unit_price\",StringType(),True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_items = spark.createDataFrame(data = order_items,schema = schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- item_id: string (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- quantity: string (nullable = true)\n",
      " |-- unit_price: string (nullable = true)\n",
      "\n",
      "+--------+-------+----------+--------+----------+\n",
      "|order_id|item_id|product_id|quantity|unit_price|\n",
      "+--------+-------+----------+--------+----------+\n",
      "|1       |2      |3         |5       |49000     |\n",
      "|2       |2      |2         |5       |49000     |\n",
      "|3       |3      |3         |5       |49000     |\n",
      "|4       |4      |2         |6       |49000     |\n",
      "+--------+-------+----------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_items.printSchema()\n",
    "order_items.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Orders_data = [(1,8,\"in progress\",2,\"2021\"),\n",
    "             (2,9,\"pending\",3,\"2021\"),\n",
    "             (3,11,\"arrived\",2,\"2021\"),\n",
    "             (4,12,\"pending\",5,\"2021\"),\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"order_id\",IntegerType(),True),\n",
    "    StructField(\"customer_id\",StringType(),True),\n",
    "    StructField(\"status\",StringType(),True),\n",
    "    StructField(\"salesman_id\",IntegerType(),True),\n",
    "    StructField(\"order_date\",StringType(),True),\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- salesman_id: integer (nullable = true)\n",
      " |-- order_date: string (nullable = true)\n",
      "\n",
      "+--------+-----------+-----------+-----------+----------+\n",
      "|order_id|customer_id|status     |salesman_id|order_date|\n",
      "+--------+-----------+-----------+-----------+----------+\n",
      "|1       |8          |in progress|2          |2021      |\n",
      "|2       |9          |pending    |3          |2021      |\n",
      "|3       |11         |arrived    |2          |2021      |\n",
      "|4       |12         |pending    |5          |2021      |\n",
      "+--------+-----------+-----------+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Orders_data=spark.createDataFrame(data = Order1_data,schema=schema)\n",
    "Orders_data.printSchema()\n",
    "Orders_data.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Orders_data.createOrReplaceTempView(\"Orders_data\")\n",
    "order_items.createOrReplaceTempView(\"order_items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(7) Sort [year#374 ASC NULLS FIRST], true, 0\n",
      "+- Exchange rangepartitioning(year#374 ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [id=#581]\n",
      "   +- *(6) HashAggregate(keys=[year(cast(order_date#177 as date))#380], functions=[sum((cast(quantity#145 as double) * cast(unit_price#146 as double)))])\n",
      "      +- Exchange hashpartitioning(year(cast(order_date#177 as date))#380, 200), ENSURE_REQUIREMENTS, [id=#577]\n",
      "         +- *(5) HashAggregate(keys=[year(cast(order_date#177 as date)) AS year(cast(order_date#177 as date))#380], functions=[partial_sum((cast(quantity#145 as double) * cast(unit_price#146 as double)))])\n",
      "            +- *(5) Project [quantity#145, unit_price#146, order_date#177]\n",
      "               +- *(5) SortMergeJoin [order_id#142], [order_id#173], Inner\n",
      "                  :- *(2) Sort [order_id#142 ASC NULLS FIRST], false, 0\n",
      "                  :  +- Exchange hashpartitioning(order_id#142, 200), ENSURE_REQUIREMENTS, [id=#562]\n",
      "                  :     +- *(1) Project [order_id#142, quantity#145, unit_price#146]\n",
      "                  :        +- *(1) Filter isnotnull(order_id#142)\n",
      "                  :           +- *(1) Scan ExistingRDD[order_id#142,item_id#143,product_id#144,quantity#145,unit_price#146]\n",
      "                  +- *(4) Sort [order_id#173 ASC NULLS FIRST], false, 0\n",
      "                     +- Exchange hashpartitioning(order_id#173, 200), ENSURE_REQUIREMENTS, [id=#568]\n",
      "                        +- *(3) Project [order_id#173, order_date#177]\n",
      "                           +- *(3) Filter isnotnull(order_id#173)\n",
      "                              +- *(3) Scan ExistingRDD[order_id#173,customer_id#174,status#175,salesman_id#176,order_date#177]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select year(order_date) as year,sum(quantity*unit_price) as revenue from order_items i NATURAL JOIN Orders_data d  group by year(order_date) order by year\").explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
